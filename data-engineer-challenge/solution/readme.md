# Setup
For simplicity the instructions assume you're running on OS X with [homebrew|https://brew.sh/] [installed|https://docs.brew.sh/Installation] and working properly. I'm also assuming that this is not geared towards a production system but rather a quick exploration into Kafka and related concepts. What follows are (lengthy) the steps I took to get everything setup and running. I recommend to skip the steps which are already satisfied on your machine (ðŸ‘‹pyenv etc.).
1. Install a Java version
    ```sh
    $ brew cask install homebrew/cask-versions/adoptopenjdk8
    ```
2. Install Kafka (and it's dependencies)
    ```sh
    $ brew install kafka
    ```
3. Install Pyenv via the description found here: https://github.com/pyenv/pyenv#homebrew-on-macos. 
Running `pyenv versions` in your shell should show at least the `system` version.
4. Install python 3.8.5 by running
    ```sh
    $ pyenv install 3.8.5
    ```
5. Install the virtualenv pyenv plugin and follow the _Caveats_ section to properly initialize it in your shell.
    ```sh
    $ brew install pyenv-virtualenv
    ```
6. Create a virtual environment and install the project dependencies
    ```sh
    $ pyenv virtualenv 3.8.5 doodle-challenge
    $ pyenv activate doodle-challenge
    $ pip install -r requirements.txt
    ```

# Solution
My solution borrows code and other functionality from a few places which are cited appropriately.
### Kafka
In order to start the kafka server and the necessary Zookeeper server I simply copied the instructions from the _caveats_ section of the _brew_ formula. For convenience you can just execute the `start-kafka.sh` shell script:
```sh
$ ./start-kafka.sh
```
Please check the logs for any exceptions. If you see any, unfortunately you're on your own and need to resolve them.

#### Download the test data
As the Readme of the challenge mentioned example data can be found either online or generated by using the provided source code. I chose to simply download the data using
```sh
$ wget http://tx.tamedia.ch.s3.amazonaws.com/challenge/data/stream.jsonl.gz
```

#### Import the test data
This is simply copied from the ReadMe of the challenge. Please note that I named the kafka topic `doodle-challenge`. Since the topic doesn't exist before writing the messages it is automatically created. So no extra step here is needed.
```sh
$ gzcat stream.jsonl.gz | kafka-console-producer --broker-list localhost:9092 --topic doodle-challenge
```
This might take a while :coffee: - at least on my machine from 2015.

You can check if the topic was created successfully by executing the following and checking the output for `doodle-challenge`:
```sh
$ kafka-topics --list --botstrap-server localhost:9092
```

#### Execute the basic solution
This is as simple as I could imagine it to be. Just run the following:
```sh
$ ./basic_consumer.py
```
Below is an excerpt of a possible output where the first part before the comma denotes the respective minute and the second part shows the number of unique users "tracked" during that minute.
```
2016-07-11 13:41:00, 47369
2016-07-11 13:42:00, 49488
2016-07-11 13:43:00, 47863
2016-07-11 13:44:00, 40439
```